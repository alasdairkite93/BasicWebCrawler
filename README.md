# BasicWebCrawler
 A basic web crawler using breadth first search

Basic web crawler uses breath first search to crawl web page URLs. Basic web crawler comes with a depth feature providing users with the ability to adjust queue depth. Basic web crawler also contains seeds.txt file and output.txt file for users to add seeds and access results. Basic web crawler is able to be used for internal links of web pages and is not configured for use of external links. Basic web crawler uses a basic modular structure and is designed using a basic crawler framework. 
